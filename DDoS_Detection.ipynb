{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_path = \"./datasets/ddos_balanced/final_dataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(path, p=0.1):\n",
    "  df_dataset = pd.read_csv(path, skiprows=lambda i: i>0 and random.random() > p)\n",
    "\n",
    "  colToDrop = np.array(['Unnamed: 0','Flow ID', 'Src IP', 'Dst IP', 'Timestamp'])\n",
    "  df_dataset = df_dataset.drop(colToDrop, axis=1)\n",
    "  df_dataset.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "  df_dataset.dropna(inplace=True)\n",
    "\n",
    "  df_dataset.replace(to_replace=\"Benign\", value=0, inplace=True)\n",
    "  df_dataset.replace(to_replace=\"ddos\", value=1, inplace=True)\n",
    "\n",
    "  return df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(df_dataset):\n",
    "       from plotly.offline import init_notebook_mode, iplot, plot\n",
    "       import plotly as py\n",
    "       import plotly.express as px\n",
    "       init_notebook_mode(connected=True)\n",
    "       import plotly.graph_objs as go\n",
    "\n",
    "       fig = go.Figure(data=[\n",
    "       go.Bar(name='Benign', \n",
    "              y=df_dataset[\"Label\"].value_counts().values[0:1],\n",
    "              x=['Benign'],\n",
    "              text = df_dataset[\"Label\"].value_counts()[0:1],\n",
    "              orientation='v',\n",
    "              textposition='outside',),\n",
    "       go.Bar(name='DDoS', \n",
    "              y=df_dataset[\"Label\"].value_counts().values[1:2],\n",
    "              x=['ddos'],\n",
    "              text = df_dataset[\"Label\"].value_counts()[1:2],\n",
    "              orientation='v',\n",
    "              textposition='outside',)\n",
    "       ])\n",
    "\n",
    "       fig.update_layout(\n",
    "                     width=800,\n",
    "                     height=600,\n",
    "                     title=f'Class Distribution',\n",
    "                     yaxis_title='Number of attacks',\n",
    "                     xaxis_title='Attack Name',)\n",
    "       iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(train, test):\n",
    "       from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "       numerical_columns = ['Flow Duration', 'Tot Fwd Pkts',\n",
    "              'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max',\n",
    "              'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std',\n",
    "              'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean',\n",
    "              'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean',\n",
    "              'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot',\n",
    "              'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min',\n",
    "              'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max',\n",
    "              'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags',\n",
    "              'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s',\n",
    "              'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean',\n",
    "              'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt',\n",
    "              'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt',\n",
    "              'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg',\n",
    "              'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg',\n",
    "              'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg',\n",
    "              'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts',\n",
    "              'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts',\n",
    "              'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts',\n",
    "              'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max',\n",
    "              'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']\n",
    "\n",
    "       min_max_scaler = MinMaxScaler().fit(train[numerical_columns])\n",
    "       train[numerical_columns] = min_max_scaler.transform(train[numerical_columns])\n",
    "       test[numerical_columns] = min_max_scaler.transform(test[numerical_columns])\n",
    "\n",
    "       return train, test\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNN_model(input_size):\n",
    "  neuralNetworkModel = keras.Sequential([\n",
    "    layers.InputLayer(shape=(input_size,)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(rate = 0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(rate = 0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(rate = 0.3),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "  ])\n",
    "\n",
    "  print(neuralNetworkModel.summary())\n",
    "  return neuralNetworkModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model():\n",
    "  from sklearn.svm import SVC\n",
    "  return SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_model():\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  return LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianNB_model():\n",
    "  from sklearn.naive_bayes import GaussianNB\n",
    "  return GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest_model():\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  return RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecisionTree_model():\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  return DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model, X_train, y_train, isDL=True):\n",
    "    if isDL:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, epsilon=0.01)\n",
    "\n",
    "        early_stopping = callbacks.EarlyStopping(\n",
    "            monitor='loss', \n",
    "            min_delta = 0.001,\n",
    "            patience = 5,\n",
    "            restore_best_weights = True\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['binary_accuracy'],\n",
    "        )\n",
    "        history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size = 256,\n",
    "        callbacks=[early_stopping]\n",
    "        )\n",
    "\n",
    "        # summarize history for accuracy\n",
    "        plt.plot(history.history['binary_accuracy'])\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['train'], loc='upper left')\n",
    "        plt.show()\n",
    "        # summarize history for loss\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['train'], loc='upper left')\n",
    "        plt.show()\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X_test, y_test):\n",
    "    from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score, accuracy_score\n",
    "    import seaborn as sns\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.round(y_pred)\n",
    "\n",
    "    # Accuracy \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print('\\nAccuracy')\n",
    "    print(acc)\n",
    "\n",
    "    # Precision \n",
    "    prec = precision_score(y_test, y_pred)#,average='macro')\n",
    "    print('\\nPrecision')\n",
    "    print(prec)\n",
    "\n",
    "    # Recall\n",
    "    rec = recall_score(y_test, y_pred) #,average='macro')\n",
    "    print('\\nRecall')\n",
    "    print(rec)\n",
    "\n",
    "    # F1 score\n",
    "    f1 = f1_score(y_test,y_pred) #,average='macro')\n",
    "    print('\\nF1 Score')\n",
    "    print(f1)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    print('\\nConfusion Matrix')\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cf_matrix, annot=True, fmt='g')\n",
    "\n",
    "    return acc, prec, rec, f1, cf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_processing(dataset_path)\n",
    "plot_class_distribution(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE_SEED = 1\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=RANDOM_STATE_SEED)\n",
    "\n",
    "print(\"Full dataset:\\n\")\n",
    "print(\"Benign: \" + str(df[\"Label\"].value_counts()[[0]].sum()))\n",
    "print(\"DDoS: \" + str(df[\"Label\"].value_counts()[[1]].sum()))\n",
    "print(\"---------------\")\n",
    "\n",
    "print(\"Training set:\\n\")\n",
    "print(\"Benign: \" + str(train[\"Label\"].value_counts()[[0]].sum()))\n",
    "print(\"DDoS: \" + str(train[\"Label\"].value_counts()[[1]].sum()))\n",
    "y_train = np.array(train.pop(\"Label\"))\n",
    "X_train = train.values\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"---------------\")\n",
    "\n",
    "print(\"Test set:\\n\")\n",
    "print(\"Benign: \" + str(test[\"Label\"].value_counts()[[0]].sum()))\n",
    "print(\"DDoS: \" + str(test[\"Label\"].value_counts()[[1]].sum()))\n",
    "y_test = np.array(test.pop(\"Label\"))\n",
    "X_test = test.values\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_features = X_train.shape[1]\n",
    "dnn_model = DNN_model(_features)\n",
    "dnn_model = compile_model(dnn_model, X_train, y_train)\n",
    "test_model(dnn_model, X_test ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVM_model()\n",
    "svm_model = compile_model(svm_model, X_train, y_train, isDL=False)\n",
    "test_model(svm_model, X_test ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LR_model()\n",
    "lr_model = compile_model(lr_model, X_train, y_train, isDL=False)\n",
    "test_model(lr_model, X_test ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussianNB_model = GaussianNB_model()\n",
    "gaussianNB_model = compile_model(gaussianNB_model, X_train, y_train, isDL=False)\n",
    "test_model(gaussianNB_model, X_test ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = RandomForest_model()\n",
    "random_forest_model = compile_model(random_forest_model, X_train, y_train, isDL=False)\n",
    "test_model(random_forest_model, X_test ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model = DecisionTree_model()\n",
    "decision_tree_model = compile_model(decision_tree_model, X_train, y_train, isDL=False)\n",
    "test_model(decision_tree_model, X_test ,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
